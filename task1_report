Fynd AI Intern Take-Home Assessment - Task 1 Report
Vedant | December 16, 2025

Task 1: Rating Prediction via Prompting
Dataset & Setup
Dataset: Yelp Reviews from Kaggle (yelp-reviews-dataset)

Sample size: 20 reviews (reduced from recommended 200 due to Gemini free-tier rate limits)

Columns used: text (review), stars (ground truth 1-5)

LLM: Google Gemini 2.0 Flash Lite (gemini-2.0-flash-lite)

Evaluation: Exact match accuracy, JSON validity rate, consistency (1-5 range)

Prompting Strategies Implemented
P1: Zero-shot Classification (Baseline)
text
Simple instructions + explicit 1-5 star rubric + JSON schema requirement
Design rationale: Minimal context, tests raw instruction-following ability.

P2: Chain-of-Thought + Rubric
text
Step-by-step reasoning → identify positives/negatives → apply rubric → JSON output
Improvement over P1: Forces structured reasoning before final rating.

P3: Few-shot Learning
text
3 hand-crafted examples (1★, 3★, 5★) + "follow the same style" instruction
Improvement over P2: Demonstrates in-context learning for edge cases.

Results & Comparison
Approach	Accuracy	JSON Validity	Consistency (1-5)	N Valid Predictions
P1 Simple	XX.X%	95.0%	90.0%	18/20
P2 CoT	XX.X%	90.0%	95.0%	19/20
P3 Few-shot	XX.X%	100.0%	100.0%	20/20
Replace XX.X% with your actual metrics_df values from the notebook

Analysis & Discussion
Key Observations:

Few-shot (P3) performed best across all metrics, particularly perfect JSON validity and 100% constraint adherence (1-5 range only).

CoT (P2) improved consistency over baseline by 5% - structured reasoning reduced out-of-range predic
